---
title: "Qualitative Analysis of Dumbbell Exercise"
output:
  html_document:
    toc: true
    toc_depth: 5
---

### Objective

This document tries to study existing data, create model and predict quality of dumbbell exercise performed by multiple participants.

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. 
These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, 
to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, 
but they rarely quantify how well they do it.

Participants were asked to perform one set of 10 repetitions
of the Unilateral Dumbbell Biceps Curl in Five different fash-
ions: exactly according to the specification (Class A), throw-
ing the elbows to the front (Class B), lifting the dumbbell
only halfway (Class C), lowering the dumbbell only halfway
(Class D) and throwing the hips to the front (Class E). Class
A corresponds to the specified execution of the exercise,
while the other 4 classes correspond to common mistakes.
Participants were supervised by an experienced weight lifter
to make sure the execution complied to the manner they
were supposed to simulate. The exercises were performed by
six male participants aged between 20-28 years, with little
weight lifting experience. We made sure that all participants
could easily simulate the mistakes in a safe and controlled
manner by using a relatively light dumbbell (1.25kg).


The existing training data for this project are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The new test data to test the model are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

These data come from the following source. We give people from this source full credit to share the data with us.

http://groupware.les.inf.puc-rio.br/har. 

### Identify the Features

We have defined and differentiated between the rightly and wrongly done exercises. We can gauge from the numbers if the exercise
was done in the right manner or not. The accelerometer on arm can indicate that the exercise falls in Class B category or not. 
Gyroscope and magnetometer readings doesn't make sense here considering the possible elbow movements.Class B and D can be gauged 
from the readings of dumbbell parameters of accelerometer, gyroscope and magnetometer. There can be some correlation between the 
accelerometer and magnetometer readings as both are related to earth's forces. Class E can be gauged from the belt readings. 
Most of the readings form the features, excluding the aggregated ones like average, sd, variance, others, etc.

### Data Processing

*. Read the training and test data. 
*. Filter the data horizontally and vertically as per the selected features.
*. No NAs are found in the variables
*. Partition the training data. 
*. No near zero variance variables found
*. ??? Preprocessing

```{r}
library(caret)
library(doParallel)

set.seed(300)
tr<-read.csv("pml-training.csv")

registerDoParallel(cores=detectCores(all.tests=TRUE))
                   
tr<-subset(tr,new_window=="no")
tr<-subset(tr,subset=T,select=c(roll_belt,pitch_belt,yaw_belt,total_accel_belt,gyros_belt_x,gyros_belt_y,gyros_belt_z,accel_belt_x,accel_belt_y,accel_belt_z,magnet_belt_x,magnet_belt_y,magnet_belt_z,total_accel_arm,accel_arm_x,accel_arm_y,accel_arm_z,magnet_arm_x,magnet_arm_y,magnet_arm_z,roll_dumbbell,pitch_dumbbell,yaw_dumbbell,total_accel_dumbbell,gyros_dumbbell_x,gyros_dumbbell_y,gyros_dumbbell_z,accel_dumbbell_x,accel_dumbbell_y,accel_dumbbell_z,magnet_dumbbell_x,magnet_dumbbell_y,magnet_dumbbell_z,pitch_forearm,yaw_forearm,roll_forearm,gyros_forearm_x,gyros_forearm_y,gyros_forearm_z,classe))

inTr<-createDataPartition(y=tr$classe,p = .3,list=F)

tr2<-tr[inTr,]

#predictors
ps<-tr2[,1:dim(tr2)[2]-1]
#outcomes
os<-tr2[,dim(tr2)[2]]

#are any predictors varying very little to be insignificant
nzv<-nearZeroVar(ps)
nzv

```

### Training the Model

* 5-fold cross validation suits this case during the training process
* We need to select some classification model
* There can be some strong and weak predictors due to overlap because of earth's forces. So Random Forest with bagging model 
suits better.


```{r}
fitControl<-trainControl(method="cv", number=5)
rfFit<-train(x=psPC,y=as.factor(os),method="rf",trControl=fitControl,prox=T,allowParallel=T)

```

### Model/Fit Analysis

```{r}
rfFit
```

It confirms what we are trying to do in terms of resampling, preprocessing, cross validation information, count of trees 
and accuracy output. The model has selected various mtry options (count of predictors selected in each split). 
The best, most accurate one, will be selected.

The model is ready to be tested.

### Testing the Model

```{r}
ts2<-tr[-inTr,]
#predictors
psts3<-ts2[,1:dim(ts2)[2]-1]
psts3<-predict(pp,psts3)
#outcomes
osts<-ts2[,dim(ts2)[2]]
pred<-predict(rfFit,psts3)
confusionMatrix(pred,osts)

```

The most important parameter is:
Accuracy: ???

It confirms our good faith in the model.


